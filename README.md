# Space Apps Earth Data - Air Quality Monitoring Platform

A comprehensive air quality monitoring and prediction platform using NASA TEMPO satellite data, machine learning, and real-time visualization.

## ğŸŒ Project Overview

This project leverages NASA's TEMPO (Tropospheric Emissions: Monitoring of Pollution) satellite data to monitor and predict air quality across North America, with a focus on NO2, HCHO, and O3 levels. The platform combines machine learning models with real-time data visualization and an AI-powered chatbot assistant.

## ğŸ—ï¸ Project Structure

```
space-apps-earth-data/
â”œâ”€â”€ backend/               # FastAPI backend server
â”‚   â”œâ”€â”€ main.py           # API endpoints and ML model serving
â”‚   â”œâ”€â”€ models/           # Trained ML models (.keras, .h5, .pkl)
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ front-end/            # Next.js frontend application
â”‚   â”œâ”€â”€ app/              # Next.js app directory
â”‚   â”‚   â”œâ”€â”€ api/         # API routes
â”‚   â”‚   â”œâ”€â”€ chat/        # AI chatbot interface
â”‚   â”‚   â”œâ”€â”€ map/         # Interactive map view
â”‚   â”‚   â””â”€â”€ report/      # Reporting interface
â”‚   â”œâ”€â”€ components/       # React components
â”‚   â””â”€â”€ public/          # Static assets
â”œâ”€â”€ data/                 # Data processing scripts
â”‚   â”œâ”€â”€ tempo_data_utils.py  # TEMPO data extraction utilities
â”‚   â”œâ”€â”€ extract_data.py      # NetCDF to CSV converter
â”‚   â””â”€â”€ tempo_no2_data.csv   # Processed data
â”œâ”€â”€ ml/                   # Machine learning development
â”‚   â””â”€â”€ notebooks/       # Jupyter notebooks for ML experiments
â””â”€â”€ .env                 # Environment variables (not in git)
```

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.8+** (for backend and data processing)
- **Node.js 18+** and npm (for frontend)
- **NASA Earthdata Account** (for TEMPO data access)
- **Google Gemini API Key** (for AI chatbot)

### Backend Setup

1. **Navigate to backend directory:**
   ```bash
   cd backend
   ```

2. **Create a virtual environment:**
   ```bash
   python -m venv venv
   # Windows
   venv\Scripts\activate
   # macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables:**
   Create a `.env` file in the root directory:
   ```env
   GEMINI_API_KEY=your_gemini_api_key_here
   ```

5. **Start the backend server:**
   ```bash
   uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
   ```

### Frontend Setup

1. **Navigate to frontend directory:**
   ```bash
   cd front-end
   ```

2. **Install dependencies:**
   ```bash
   npm install
   ```

3. **Start the development server:**
   ```bash
   npm run dev
   ```

4. **Open your browser:**
   Navigate to `http://localhost:3000`

### Combined Startup (from root)

```bash
npm run dev
```

This will start both the backend (port 8000) and frontend (port 3000).

## ğŸ”‘ API Keys Setup

### NASA Earthdata Login

1. Register at [NASA Earthdata](https://urs.earthdata.nasa.gov/users/new)
2. Create a `.netrc` file in your home directory with your credentials
3. The `earthaccess` library will use these credentials automatically

### Google Gemini API

1. Get an API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Add it to your `.env` file:
   ```env
   GEMINI_API_KEY=your_api_key_here
   ```

## ğŸ“Š Data Processing

### Extracting TEMPO Satellite Data

```python
from data.tempo_data_utils import authenticate_earthaccess, search_tempo_data, load_tempo_dataset

# Authenticate with NASA Earthdata
authenticate_earthaccess()

# Search for NO2 data
results = search_tempo_data('TEMPO_NO2_L3', count=5)

# Load and process
dataset = load_tempo_dataset(results, index=0)
```

### Converting NetCDF to CSV

```python
from data.tempo_data_utils import extract_netcdf_to_csv

df = extract_netcdf_to_csv(
    input_file='TEMPO_NO2_L2_V03_20240717T232209Z_S015G06.nc',
    output_csv='tempo_no2_data.csv'
)
```

## ğŸ¤– API Endpoints

### Backend API (Port 8000)

- **GET** `/` - Health check
- **POST** `/predict-no2` - Predict NO2 levels
  ```json
  {
    "values": [1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1]
  }
  ```
- **POST** `/chat` - AI chatbot for air quality advice

### Frontend API Routes (Port 3000)

- `/api/ai` - AI assistant interface
- `/api/openaq` - OpenAQ data integration
- `/api/report` - Air quality reporting

## ğŸ§ª Machine Learning Models

### NO2 Prediction Model

- **Type:** LSTM/Time Series
- **Input:** 10 previous NO2 measurements
- **Output:** Next NO2 value prediction
- **Location:** `backend/models/no2_pred_10_window_newer.keras`

### AQI Forecasting Model

- **Type:** Multi-feature forecasting
- **Location:** `backend/models/aqi_forecaster_model.h5`

## ğŸ› ï¸ Technologies Used

### Backend
- **FastAPI** - Modern Python web framework
- **TensorFlow/Keras** - Machine learning models
- **Google Generative AI** - AI chatbot
- **Pandas & NumPy** - Data processing
- **xarray & netCDF4** - Satellite data processing

### Frontend
- **Next.js 15** - React framework
- **TypeScript** - Type-safe JavaScript
- **Tailwind CSS** - Utility-first styling
- **D3.js** - Data visualization
- **Radix UI** - Accessible component primitives

## ğŸ“ Development

### Running Jupyter Notebooks

```bash
cd ml/notebooks
jupyter notebook
```

Available notebooks:
- `data.ipynb` - Data exploration
- `new_stuff.ipynb` - Latest experiments
- `stuff.ipynb` - Model development

### Code Quality

The project uses:
- **ESLint** for JavaScript/TypeScript linting
- **Python type hints** for backend type safety
- **Prettier** (recommended) for code formatting

## ğŸŒ Deployment

### Backend Deployment

The backend can be deployed to:
- **Heroku** - Using `Procfile`
- **Google Cloud Run** - Containerized deployment
- **AWS Lambda** - Serverless deployment

### Frontend Deployment

The Next.js app is optimized for deployment on:
- **Vercel** (recommended)
- **Netlify**
- **AWS Amplify**

## ğŸ“„ License

ISC

## ğŸ¤ Contributing

This is a NASA Space Apps Challenge project. For contributions, please follow standard GitHub flow:

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“§ Contact

Repository: [github.com/nimnay/space-apps-earth-data](https://github.com/nimnay/space-apps-earth-data)

## ğŸ™ Acknowledgments

- **NASA** - For TEMPO satellite data
- **Space Apps Challenge** - For the opportunity
- **OpenAQ** - For air quality data API
- **Google Gemini** - For AI capabilities
